# Text-Augmented Open Knowledge Graph Completion via Pre-Trained Language Models

> 通过预先训练的语言模型完成文本增强开放知识图谱

[toc]

---

## 摘要

现有知识图谱补全方法：

- 现有事实三元组扩大图推理空间；
- 手动设计提示从PLM中提取知识；

> 缺点：性能有限，需要专家知识

文章提出TagReal方法，自定生成高质量查询提示，从大型文本语料库中检索**支持信息**，在从PLM中探索知识。



## 1 介绍

<img src="./Text-Augmented%20Open%20Knowledge%20Graph%20Completion%20via%20Pre-Trained%20Language%20Models.assets/image-20231204141302631.png" alt="image-20231204141302631" style="zoom:50%;" />

知识图谱补全：

- 大多数大规模KG不完整；
- KG补全：在给定实体和关系的情况下找到一个或多个对象实体；

现有知识图谱补全方法限制：

- 在丰富结构信息的密集图上表现良好，反之表现不佳；
- 只假设在封闭世界的KG上，不考虑大量的开放知识；

现有PLM-KG知识补全方法：

- 手动设计提示：代价高昂且质量有限；

TagReal模型：

- 端到端框架联合利用plm中的隐性知识和语料库中的文本信息来执行知识图谱补全；
- 开发提示自动生成和信息检索的方法；



## 2 相关工作

### 2.1 KG补全方法

基于嵌入的方法：

- 将实体和关系表示为嵌入向量；
- TransE、DistMult、RotatE；

基于PLM的方法：

- 用提示和支持信息作为PLM输入完成知识图谱补全；

TagReal模型KG补全方法：

- 不需要任何领域专家知识的情况下自动生成更高质量的提示；
- 采用信息检索的方法从语料库中搜索相关的文本信息，而不是预先假设支持信息的存在；

### 2.2 利用提示探索知识

- LAMA：用占位符和对象未填充空间来构成提示；
- BertNet：利用GPT-3自动生成带有权重的提示集合；

### 2.3 提示挖掘方法

- MINE：在大型文本语料库(例如Wikipedia)中搜索给定输入和输出之间的中间词或依赖路径；通过加权提示个体在PLM上的表现来优化挖掘提示的集合；
- MetaPAD：通过带有模式质量函数的上下文感知分割生成高质量的元模式；
- TruePIE：提出了模式嵌入和自我训练框架的概念，可以自动发现正确提示模式；



## 3 方法

<img src="./Text-Augmented%20Open%20Knowledge%20Graph%20Completion%20via%20Pre-Trained%20Language%20Models.assets/image-20231204145029081.png" alt="image-20231204145029081" style="zoom:50%;" />

> 红色为输入、绿色为输出

### 3.1 任务符号化

KG补全：向已知三元组集合中添加新的三元组

- 分类任务：三元组$(h,r,t)$是否属于KG；
- 链接预测：查询尾部实体$(h,r,?)$或者查询头部实体$(?,r,t)$；

### 3.2 提示生成

将KG中的三元组作为唯一的输入，使用文本模式挖掘方法从大型语料库中挖掘质量模式，适用原因：

- 类似的数据源；
- 类似的目标；
- 类似的性能标准；

<img src="./Text-Augmented%20Open%20Knowledge%20Graph%20Completion%20via%20Pre-Trained%20Language%20Models.assets/image-20231204151449028.png" alt="image-20231204151449028" style="zoom: 50%;" />



#### 3.2.1 子语料库挖掘

- 对于给定KG的关系集$R=(r_1,r_2,...)$，对于每个关系的所有元组$t_j$从大型语料库和其他可靠来源中搜索包含头尾的句子$s_{t_j}$（固定数量），将这些句子添加到子语料库$C_{r_i}$中；

#### 3.2.2 短语分割和频繁模式挖掘

- 使用AutoPhrase进行语料库分割，使用FP-Growth算法挖掘频繁的提示模式；

> AutoPhrase:
>
> - 
>
> TP-Growth:
>
> - 

#### 3.2.3 提示选择

- MetaPAD应用模式质量函数：
  - 频率和一致性；
  - 信息性->p1；
  - 完整性->p{m-2}；
  - 覆盖范围->p4；
- 对MetaPAD选择的提示应用TruePIE：过滤与正样本低余弦相似度的提示 $\rightarrow p_3,p_{m-1}$；

打分方式：
$$
P(y|x,r_i)=\sum^n_{j=1}w_{i,j}P_{LM}(y|x,p_{i,j})
$$

- 提示的权重由PLM优化给出

> MetaPAD:
>
> - 
>
> TruePTE:



### 3.3 支持信息的检索

<img src="./Text-Augmented%20Open%20Knowledge%20Graph%20Completion%20via%20Pre-Trained%20Language%20Models.assets/image-20231204160453070.png" alt="image-20231204160453070" style="zoom:67%;" />

- 支持信息在TagReal中是可选的，如果没有匹配的数据，将其保留为空；

### 3.4 训练

 TAGREAL框架的训练过程主要包括以下几个步骤：

1. **创建负样本**：为了处理三元组分类任务，需要为训练集创建负样本。这可以通过替换正样本中的头实体和尾实体来实现。首先，使用TuckER等知识图谱嵌入（KGE）模型创建负样本。然后，通过随机替换头实体和尾实体来生成随机负样本。将正负样本合并以构建训练集。

2. **生成查询实例**：将所有训练三元组转换为句子形式，使用优化后的提示集合和三元组支持信息（如果有的话）。在训练过程中，[MASK]将被对象实体替换。查询实例用于微调预训练语言模型（PLM）。

3. **微调PLM**：使用创建的查询实例对PLM进行微调。这将帮助PLM学习如何根据给定的提示和支持信息对三元组进行分类。在微调过程中，使用交叉熵损失函数进行优化。

4. **计算损失**：在训练过程中，计算模型在训练集上的损失。损失函数如下：

   L = - Σ(τ∈T) (yτ * log(c1τ) + (1 - yτ) * log(c0τ))

   其中，c0τ和c1τ分别表示[CLS]标记的softmax分类分数，用于三元组τ的负类和正类；yτ是三元组τ的Ground Truth标签（1表示正例，0表示负例）；M是正负样本数量之比。通过最小化损失函数，可以优化模型参数以提高三元组分类性能。

5. **推断**：在训练和微调PLM之后，可以使用推断阶段为知识图谱完成任务生成预测结果。给定一个查询（如（实体1，关系，?）），将支持信息（如果有的话）与优化后的提示集合连接起来，形成输入序列。将这个序列输入到微调后的PLM中，PLM将为每个可能的尾实体分配一个分类分数。根据分数对实体进行排序，选取排名靠前的实体作为预测结果。

通过这些训练步骤，TAGREAL能够有效地利用预训练语言模型的隐含知识，结合自动生成的提示和检索到的支持信息，实现知识图谱完成任务。在训练过程中，模型学会了如何根据给定的提示和支持信息对三元组进行分类，从而提高了知识图谱完成的性能。
