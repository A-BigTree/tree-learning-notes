# 知识推理

[toc]

---

[知识图谱推理中的常用方法、关键问题、评测指标与开放数据总结](https://mp.weixin.qq.com/s/LPN_kX-GfPUl5sqNLhz4_w)

知识推理是从已有的知识出发，得出未知的、隐性的知识，具体到知识图谱中，即利用图谱中现有的知识（三元组），得到一些新的实体间的关系或者实体的属性（三元组）。

## 1 知识图谱领域中的知识推理

知识图谱中的推理知识推理是指根据知识图谱中已有的知识，采用某些方法，推理出新的知识（知识图谱补全）或识别知识图谱中错误的知识（知识图谱去噪），前者专注于扩充知识图谱，后者专注于知识图谱内部已有三元组正确性的判断。

进一步的，知识图谱补全，是给定三元组中任意两个元素，试图推理出缺失的另外一个元素。包括**连接预测、实体预测、关系预测、属性预测。**其中：实体预测指**给定头实体和关系(关系和尾实体)，找出与之形成有效三元组的尾实体(头实体)**。例如，已知(h,r)预测t，一种是在原KG中h存在r这条边，但在测试集的t不在(h,r)后（缺失答案实体）。

关系预测指**给定头实体和尾实体，找出与之形成有效三元组的关系**。原KG中的h不存在r这条边（缺失边）。

不过，无论实体预测还是关系预测，最后都转化为选择与给定元素形成的三元组更可能有效的实体/关系作为推理预测结果，这种有效性可以通过规则的方式推理或通过基于特定假设的得分函数计算。而知识图谱去噪，实际上是在判断三元组的正确与否。

知识图谱补全任务模型主要有基于<u>**表示学习**</u>和基于<u>**规则**</u>两种。基于表示学习的方法先通过表示学习得到知识图谱中实体和关系的表示，然后利用得分函数对候选实体进行打分排序，选取得分最高的候选实体作为正确实体。



## 2 符号化推理中的规则生成

基于规则路径的方法对路径建模并进行路径查找补全图谱。前者有较强的特征表示能力，后者有较强的推理能力，其思想在于将推理的过程变成推理规则的应用过程，包括推理规则学习（推理规则库）和推理规则的执行（推理机）两个组成部分。

如何将推理规则进行符号化和规模化，是推理规则库建设的核心工作，传统的归纳推理方法，根据部分对象所具有的性质来推出一类事物中所有对象都具备这类性质，==**<u>从实例抽象到一般规律</u>**==，就是其中的一个重要方法。

> 例如，通过“金受热后体积膨胀”、“银受热后体积膨胀”、“铜受热后体积膨胀”、“铁受热后体积膨胀”等例子，得到“金属受热后体积膨胀”的规则，这种从大量实例中总结出推理规则是实现规则扩充的重要手段，既可以通过专业人员手工定义、编辑，也可以通过机器挖掘，如频繁子图挖掘的方法进行处理。

### 2.1 基于手工定义的规则生成

- Cyc

- WordNet（词义消歧）

- ConceptNet

### 2.2 基于频繁挖掘的规则生成

频繁子图等机器挖掘规则方式，其思想在于获取知识图谱的规则实例，**通过将规则实例中的实体替换成变量**(或者叫符号化)，同时设定一些约束条件，以快速生成推理规则集合。



## 3 代表性规则推理系统⭐

目前，已经出现了一些典型的知识图谱推理系统，如基于OWL的推理规则引擎Apache-Jena、使用专门的逻辑编程语言，如LISP、Prolog等的编程推理、有使用Neo4j图数据库的查询推理三种。

### 3.1 基于OWL本体的规则推理

基于OWL网络本体语言的大规模分布式推理系统通过在构建知识图谱本体时定义本体，设计了类、属性或者关系间的传导关系，自动对实例进行推理操作。

### 3.2 基于逻辑编程语言的编程推理

利用推理语言在知识推理也得到了很广泛的应用，例如LISP和PROLOG。其中，PROLOG是最具代表性应用最广的人工智能语言之一，只要给出事实和规则，它会自动分析其中的逻辑关系，然后给出答案。

### 3.3 基于Neo4j子图信息的查询推理

使用Neo4j等图数据库来解决推理问题是当前业务推理问题的重要问题，但与本体推理组件Apache jena不同，Neo4j图数据库本身不具备推理能力，而是以查询的方式来对推理过程进行建模，需要人工定义好推理模式，完成子图匹配推理。



## 4 基于学习的知识图谱推理⭐

基于分布式表示的推理首先通过表示模型学习知识图谱中的事实元组， 得到知识图谱的低维向量表示；然后， 将推理预测转化为基于表示模型的简单向量操作。

### 4.1 基于转移的表示知识推理

<img src="./1-%E7%9F%A5%E8%AF%86%E6%8E%A8%E7%90%86.assets/image-20231120173823389.png" alt="image-20231120173823389" style="zoom:50%;" />

#### 4.1.1 TransE

TransE的主要思想是:如果三元组(头实体，关系，尾实体)成立，头实体向量h与关系向量r的和与尾实体向量t相近，否则远离。由上述基本转移假设得到得分函数−$||r+h−t||L1/L2$ 即，用L1或L2范数衡量距离。学习过程替换头实体或尾实体得到负例，类似支持向量机，最小化一个基于Margin的损失，使正例的得分比负例的得分至少高一个Margin。在进行推理时，得分函数取值大的候选实体/关系即为推理结果。

<img src="./1-%E7%9F%A5%E8%AF%86%E6%8E%A8%E7%90%86.assets/bd3189b2b9810431255e890d6688ecd0.png" alt="bd3189b2b9810431255e890d6688ecd0" style="zoom:50%;" />

#### 4.1.2 TransH、TransM、TransD

TransE严格要求有效的三元组满足头实体加关系在向量空间中与尾实体足够靠近，可以很好地处理一对一关系，但在处理多映射属性关系时，存在多个实体竞争一个点的现象。

TransH，在TransE的基础上为每个关系多学一个映射向量，用于将实体映射到关系指定的超平面；然后在该超平面，与TransE一样，关系表示向量看成映射后的实体之间的转移。映射向量使得对于不同关系，同一个实体在不同关系指定的超平面有不同的表示，一定程度上缓解了不能很好地处理多映射属性关系的问题。

TransM，直接根据关系的映射属性预先计算每个训练三元组的权重，用于加权损失函数。

TransD中，实体和关系均用两个向量表示，第1个指示含义，第2个动态构建映射矩阵，由此，实体的映射矩阵为对应关系和实体的第2个向量的乘积，同时考虑实体和关系的多样性。

#### 4.1.3 TKRL

`TKRL(type-embodied knowledge representation learning)`学习知识图谱实体和关系的表示，将层级类型信息用于映射矩阵、训练时负例的选择和评估时候选的过滤。

> TransE只专注于满足知识图谱中的三元组约束，然而知识图谱中存在大量层级关系，例如在知识图谱WordNet的子集WN18中，大约有50%的层级关系。

#### 4.1.4 SSE

SSE(semantically smooth embedding)学习知识图谱实体和关系的表示，利用实体语义类信息强制表示空间几何结构语义平滑。TransE-NMM(TransE-neighborhood mixture modeling)，在TransE的基础上定义基于邻居的实体表示，引入邻居实体信息进行实体和关系的表示学习。

> TransE没有考虑丰富的语义信息，缺乏对空间中向量分布位置的进一步调整。

#### 4.1.5 TEKE、cross-KG

TEKE(text-enhanced knowledge embedding)，引入文本语料中丰富的上下文信息扩展知识图谱的语义结构，学习知识图谱实体和关系的表示。TEKE通过标注文本语料中的知识图谱实体，构建实体和词的指定共现窗口的共现网络，将文本语料和知识图谱联系起来。

跨知识图谱的表示方法cross-KG，同时学习两个不同知识图谱的表示。通过映射语义相关的两个知识图谱中的实体和关系到统一的语义空间，cross-KG借助更大和更稠密知识图谱的知识，促进稀疏知识图谱的表示学习。

> TransE在单个知识图谱上进行学习推理，而单个知识图谱知识量有限。

#### 4.1.6 TransA

TransA将Margin参数分为实体和关系指定的局部Margin的加权和。

Margin和实体、关系的表示相关，不同知识图谱自适应学习，而不是从指定的候选集选取。AE(time-aware embedding)，用三元组和时间信息预测知识图谱中的连接，即:给定三元组中的两个元素与时间区间，预测另一个元素。

> TransE参数的选取与知识图谱数据独立，不能反映数据的特点，并且未考虑知识的时间约束。

### 4.2 基于神经网络的推理

基于神经网络的推理利用神经网络直接建模知识图谱事实元组，得到事实元组元素的向量表示，用于进一步的推理。

该类方法依然是一种基于得分函数的方法，区别于其他方法，整个网络构成一个得分函数，神经网络的输出即为得分值。

代表性的，张量网络NTN(neural tensor network)，用双线性张量层代替传统的神经网络层，在不同的维度下，将头实体和尾实体联系起来，刻画实体间复杂的语义联系。