# Towards Semantically Enriched Embeddings for Knowledge Graph Completion

[toc]

---

在过去的几年里，基于嵌入的知识图谱（Knowledge Graph, KG）补全方法已经引起了广泛关注。知识图谱在形式上表示为实体间关系的事实，以及作为模式信息的本体论。知识图谱已经被应用于各种领域，如知识管理、表示、推理和学习等。知识图谱补全的目标是预测知识图谱中缺失的实体或关系。

知识图谱补全在各种下游任务中具有重要价值，如网络搜索、推荐系统和问答系统。近年来，大型语言模型（Large Language Models, LLMs）在自然语言处理（NLP）领域取得了革命性的进展，包括自然语言理解、问答和推理等任务。知识图谱和LLMs具有互补性，可以相互借鉴和融合以提高各自性能。

本文首先介绍了知识图谱表示方法的演变，包括基于翻译的方法、基于语义匹配的方法、基于神经网络的方法和基于路径的方法。这些方法主要关注知识图谱中的事实信息（Assertion Box, ABox），而忽略了知识图谱中的模式信息（Terminology Box, TBox）。

接下来，文章讨论了如何利用大型语言模型（LLMs）来改进知识图谱补全。将知识图谱中的结构化知识引入LLMs可以提高其在领域特定任务中的表现，同时提高知识图谱补全的效果。此外，文章还探讨了如何利用知识图谱中的类型层次信息来改进知识图谱补全，以更好地捕捉实体之间的关系。

## 知识图谱中的语义

 第二章：预备知识 - 知识图谱中的语义

知识图谱（KG）通常被定义为一组头-关系-尾三元组（h, r, t），其中h和t是图中的节点，r是从h指向t的有向边。这样，知识图谱就对应于一个有向、带标签的图，其中三元组在知识图谱中表示为带标签的边。定义1捕捉了知识图谱的图结构，但没有明确定义节点和边在知识图谱中的含义。首先，定义中没有区分知识图谱中可以存在的节点类型，即节点是否对应于实体或文本描述。这种区分存在于资源描述框架（RDF）等数据模型中，其中节点可以表示实体、带有IRI或空白节点的标签，或用于值的字面量，如字符串或不同类型的数字（整数、浮点数等）。区分实体和字面量对图的结构和节点的连接性以及图中实体和边的含义都有影响。正如我们将在第3.1节中看到的，需要专门的知识图谱嵌入模型来处理这两种类型的节点和不同类型的字面量。其次，定义1中没有提供类或关系在知识图谱中的语义（形式含义）。这通常是知识图谱中本体论的作用，它使用来自逻辑的标签或符号来指定类（或概念）和关系（或角色）的定义。不同的逻辑语言引入了不同的表达能力（见表1）。这里的表达能力是指允许的陈述复杂性，超越了关于个体的简单断言（例如，类断言）及其与其他个体或字面量的关系的断言，这些断言包含在断言框（ABox）中。更复杂的陈述包括类和角色的定义。在逻辑语言L中定义的构造和公理可以转换为标签和三元组，以便在知识图谱中进行编码。基于此，我们提供了一个考虑知识图谱中语句语义的知识图谱定义。

### 定义1（知识图谱：三元组集合定义）

一个知识图谱是一个有向、带标签的图G = (V, E, l, LG)，其中V是节点集，E是边集，LG是标签集，l是一个从V∪E到LG的映射。三元组t = (h, r, t)是一个带标签的边，即(h, r, t) = (l(h), l(r), l(t))，其中r ∈ E且h, t ∈ V。

定义1捕捉了知识图谱的图结构，但没有明确定义节点和边在知识图谱中的含义。首先，定义中没有区分知识图谱中可以存在的节点类型，即节点是否对应于实体或文本描述。这种区分存在于资源描述框架（RDF）等数据模型中，其中节点可以表示实体、带有IRI或空白节点的标签，或用于值的字面量，如字符串或不同类型的数字（整数、浮点数等）。区分实体和字面量对图的结构和节点的连接性以及图中实体和边的含义都有影响。正如我们将在第3.1节中看到的，需要专门的知识图谱嵌入模型来处理这两种类型的节点和不同类型的字面量。其次，定义1中没有提供类或关系在知识图谱中的语义（形式含义）。这通常是知识图谱中本体论的作用，它使用来自逻辑的标签或符号来指定类（或概念）和关系（或角色）的定义。不同的逻辑语言引入了不同的表达能力（见表1）。这里的表达能力是指允许的陈述复杂性，超越了关于个体的简单断言（例如，类断言）及其与其他个体或字面量的关系的断言，这些断言包含在断言框（ABox）中。更复杂的陈述包括类和角色的定义。在逻辑语言L中定义的构造和公理可以转换为标签和三元组，以便在知识图谱中进行编码。基于此，我们提供了一个考虑知识图谱中语句语义的知识图谱定义。

### 定义2（知识图谱：语义定义）

设L是一个定义概念和角色语义的逻辑语言，G = (V, E, l, LG)是一个根据定义1的知识图谱（KG）。如果LG包含L中定义的所有符号，并且G中的三元组对应于可以在L中表示的陈述，则G是一个L-KG。

通常在知识图谱中使用的逻辑语言是描述逻辑族，因为它们在表达能力和可扩展性之间提供了便利的权衡。例如，存在语言EL定义了概念交集和全存在量化的概念。扩展的EL++引入了概念交集和概念蕴涵的概念；后者对于在知识图谱中建模类层次结构是必要的。ALC相对于EL++提供了额外的表达能力，包括概念并集、否定和全量化。知识图谱中使用的更高级别的表达能力包括Web本体语言（OWL），它基于SH语言，包括更复杂的角色定义，如角色蕴涵和传递性。另一个重要的知识图谱语义方面是数据类型的概念，它包含在（D）扩展中。（D）允许对知识图谱中的字面量进行建模，这些字面量可以是断言框中的陈述的一部分。需要注意的是，基于OWL的知识图谱可以实现超出本节所述的表达能力，例如，OWL-Lite基于SHIF(D)，OWL-DL基于SHOIN(D)，OWL2基于SROIQ(D)，后者提供了角色反射性、不可反射性、不相交性和有界基数限制的定义。

## 知识图谱嵌入算法

### 基于嵌入的知识图谱表示方法

基于嵌入的知识图谱表示方法试图将知识图谱中的实体和关系映射到低维向量空间中，以便进行有效的计算和推理。这些方法可以大致分为以下几类：

#### 基于翻译的方法

（如TransE、TransH等）：这些方法将关系视为头实体和尾实体之间的翻译操作。它们学习将实体和关系映射到向量空间，使得满足三元组的实体在空间中相互靠近。

#### 基于语义匹配的方法

（如DistMult、RESCAL等）：这些方法为实体和关系分配密集向量表示，并学习计算三元组中实体和关系的匹配程度。DistMult通过将实体向量和关系矩阵相乘来计算得分，而RESCAL则通过三元组中实体的成对交互特征的加权和来计算得分。

#### 基于神经网络的方法

（如ConvE、R-GCN等）：这些方法利用神经网络（如卷积神经网络和图卷积网络）学习实体和关系的表示。ConvE使用2D卷积层学习实体和关系的向量表示，而R-GCN则通过为不同关系类型分配不同的权重矩阵来捕捉知识图谱中的关系信息。

#### 基于路径的方法

（如PTransE、GAKE等）：这些方法通过考虑知识图谱中实体之间的关系路径来捕捉实体的上下文信息。PTransE通过引入基于路径的翻译模型来扩展TransE，而GAKE则考虑从实体开始的路径信息，并利用关系感知的随机游走来学习实体和关系的表示。

### 利用大型语言模型的知识图谱表示方法

最近的研究开始探讨如何将大型语言模型（如BERT、RoBERTa等）与知识图谱表示方法相结合。这些方法通常利用预训练的语言模型为实体和关系生成表示，然后根据特定任务进行微调。例如，KG-BERT将三元组视为文本序列，并使用预训练的BERT模型计算得分。然而，这些方法仍然面临一些挑战，如如何更好地融合结构信息和语言信息，以及如何处理未见过的实体和关系。

### 利用模式信息的知识图谱表示方法

为了更好地捕捉知识图谱中的语义信息，一些方法开始利用模式信息，如类型层次结构和描述逻辑公理。这些方法试图学习能够表示概念间复杂关系（如概念交集、存在量化等）的实体和关系嵌入。例如，Box2EL方法学习将概念表示为高维盒子，以便在嵌入空间中保留尽可能多的描述逻辑语义。然而，这些方法在处理更复杂的描述逻辑时，表达能力仍然有限。

总之，知识图谱嵌入算法已经取得了显著的进展，但仍有许多挑战和未来研究方向，如提高表示的可解释性、处理大规模知识图谱以及融合多模态信息等。

## 捕捉知识图谱嵌入的语义信息

### LLM

大型语言模型在自然语言处理任务中取得了显著的成果，例如自然语言理解、问答和推理等。然而，LLMs在领域特定任务中的表现较差，且存在偏见和可解释性不足的问题。将知识图谱中的结构化知识引入LLMs可以提高其在领域特定任务中的表现，同时提高知识图谱嵌入的效果。

#### KG-BERT

KG-BERT是一种基于BERT的知识图谱嵌入方法，它将三元组视为文本序列，并使用预训练的BERT模型计算得分。尽管KG-BERT是一种LLM-based方法，但它在排名指标方面并未超过基于结构的方法，如hits@k。这可能是因为KG-BERT在处理关系方面存在不足，以及在面对词汇相似的候选实体时难以做出正确选择。

#### 多任务学习

为了解决KG-BERT的局限性，一些研究提出了多任务学习方法，将关系预测和相关性排名任务结合起来。这有助于更好地学习关系表示，从而提高知识图谱嵌入的性能。

#### 结构增强的文本表示（StAR）模型

StAR模型将每个三元组划分为两个不对称的部分，类似于基于翻译的图嵌入方法。这两个部分通过Siamese式的文本编码器进行编码。尽管这些方法在性能上有所改进，但它们仍然落后于基于结构的算法。

#### PLM-based KGC（PKGC）

PKGC方法强调了现有方法在评估设置方面的局限性，提出了一种基于手动注释的新评估指标CR@1。此外，PKGC将三元组及其支持信息转换为自然语言提示句子，从而在各种模态下实现对结构和LLM-based方法的超越。

#### GenKGC

GenKGC将知识图谱补全任务转化为序列到序列（Seq2Seq）生成任务。它利用GPT-3的上下文学习范式，通过添加相同关系的三元组示例来学习正确的输出答案。GenKGC在生成过程中引入了实体感知的分层解码器，以实现更好的表示学习和降低时间复杂度。

### 类型层次信息

类型层次结构是知识图谱中的一种模式信息，表示实体的类别及其之间的关系。为了在知识图谱嵌入中考虑类型层次结构，研究者们提出了一些方法，如TKRL、TransT和TrustE。这些方法通过在嵌入空间中对具有相同类型（或超类型）的实体进行聚类，以捕捉实体之间的语义相似性。

#### TKRL

TKRL采用分层类型编码器，利用实体类型的层次结构信息。它假设每个实体应具有多个表示其不同（超）类型的表现。通过这种方式，TKRL能更好地捕捉实体的多态性。

#### TransT

TransT方法也考虑了实体类型和其层次结构。它进一步构建了关系类型，通过计算相关实体对之间的类型层次结构相似度来捕获先验分布。然后，基于这个先验分布，为每个实体生成多个潜在表示（一组语义向量），并在不同上下文中估计实体和关系的后验概率。

#### TrustE

TrustE方法旨在构建具有元组可信度的实体类型结构化嵌入。它将实体和实体类型编码到分离的空间中，并使用结构投影矩阵。TrustE通过检测具有高可信度的实体和类型之间的成对关系来确保可信度。该模型在实体类型预测任务中进行了评估，表现良好。

这些方法在不同程度上利用了类型层次结构信息来改进知识图谱嵌入。然而，这些方法在评估基准数据集方面仍存在不足，且在处理更复杂的描述逻辑时，表达能力有限。未来的研究可以继续探索如何更好地整合类型层次结构信息，以及其他模式信息（如概念间复杂关系等），以提高知识图谱嵌入的质量。

### 描述逻辑公理

描述逻辑公理是一种表示概念间复杂关系的方法，例如概念的交集、存在量化等。为了在知识图谱嵌入中融合这些公理，研究者们提出了一些基于盒子（box）的表示方法，如Box2EL。这些方法通过将概念表示为高维盒子，以便在嵌入空间中保留尽可能多的描述逻辑语义。然而，这些方法在处理更复杂的描述逻辑时，表达能力仍然有限。

#### ELEm

ELEm是一种基于盒子的表示方法，它将EL++描述逻辑的概念表示为高维盒子，并尝试通过扩展TransE来近似解释这些概念的语义。ELEm通过学习将TransE中的实体和关系嵌入转换为盒子表示，以便更好地捕捉描述逻辑中的语义信息。

#### BoxEL和ELBE

BoxEL和ELBE在ELEm的基础上进一步扩展，通过表示概念和角色为轴对齐的盒子（BoxEL）或中心点和偏移量（ELBE），以实现更紧密的描述逻辑语义保留。这些方法还定义了针对不同描述逻辑公理的损失函数，以便在训练过程中最小化与原始逻辑语义之间的差距。

#### Box2EL

Box2EL学习概念和角色的盒子表示，以保留尽可能多的描述逻辑语义。它为每个概念和角色分配一个头盒子和尾盒子，使得头盒子中的每个点与尾盒子中的每个点通过关系向量相关联。通过这种方式，Box2EL可以更好地捕捉描述逻辑中的关系语义。

尽管这些方法在捕捉描述逻辑公理方面的表达能力有所提高，但它们在处理更复杂的描述逻辑时仍然受到限制。未来的研究可以继续探索如何扩展这些方法，以便更好地处理复杂的描述逻辑，从而提高知识图谱嵌入的质量。

## 性能评估

<img src="./Towards%20Semantically%20Enriched%20Embeddings%20for%20Knowledge%20Graph%20Completion.assets/image-20231221134316787.png" alt="image-20231221134316787" style="zoom:50%;" />