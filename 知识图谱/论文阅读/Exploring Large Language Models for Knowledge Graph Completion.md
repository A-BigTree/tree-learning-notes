# Exploring Large Language Models for Knowledge Graph Completion

> 探索知识图谱补全的大型语言模型

[toc]

---

## KGLLM模型

<img src="./Exploring%20Large%20Language%20Models%20for%20Knowledge%20Graph%20Completion.assets/image-20231221125305118.png" alt="image-20231221125305118" style="zoom:50%;" />

 方法

为了使大型语言模型（LLMs）适应知识图谱（KG）三元组，我们引入了知识图谱大型语言模型（KG-LLM），通过特定的事实问答范式对预训练的LLM进行指令微调。具体来说，我们使用知识图谱中训练三元组的提示和响应对两个开放的LLM（ChatGLM-6B和LLaMA）进行微调，分别命名为KG-ChatGLM-6B和KG-LLaMA（7B和13B）。

###  知识图谱补全任务

本章描述了知识图谱补全的三个任务：三元组分类、关系预测和实体（链接）预测，以及如何将它们转化为简单的提示问题，以便LLM完成这些任务。

#### 三元组分类

给定一个三元组$（h，r，t）$，任务是将其分类为正确或错误。例如，给定三元组“<史蒂夫·乔布斯，创立，苹果公司>”，任务是将其分类为正确。提示形成为“史蒂夫·乔布斯创立了苹果公司吗？”理想的LLM输出将是“是的，这是正确的”。

#### 关系预测

给定一个头实体和一个尾实体，任务是预测它们之间的关系。例如，给定头实体“史蒂夫·乔布斯”和尾实体“苹果公司”，任务是预测他们的关系是“创立”。提示形成为“史蒂夫·乔布斯和苹果公司之间的关系是什么？请从以下选项中选择答案：出生于|创立|是公民|……|为……效力。”理想的响应将是“史蒂夫·乔布斯创立了苹果公司”。

#### 实体（链接）预测

给定一个头实体和一个关系，任务是预测与头实体相关的尾实体。给定一个尾实体和一个关系，任务是预测与尾实体相关的头实体。例如，给定头实体“史蒂夫·乔布斯”和关系“创立”，任务是预测尾实体“苹果公司”。提示形成为“史蒂夫·乔布斯创立了……”以询问尾实体，以及“什么/谁/何时/何地/为什么创立了苹果公司？”以询问头实体。理想的响应将是“史蒂夫·乔布斯创立了苹果公司”。

### 指令微调LLM进行知识图谱补全（KG-LLM）

为了使LLM适应知识图谱三元组，我们引入了KG-LLM，通过特定的事实问答范式对预训练的LLM进行指令微调。具体来说，我们使用知识图谱中训练三元组的提示和响应对两个开放的LLM（ChatGLM-6B和LLaMA）进行微调，分别命名为KG-ChatGLM-6B和KG-LLaMA（7B和13B）。

我们使用与KG嵌入相同的实体和关系文本描述作为输入。由于访问限制，我们对GPT-4和ChatGPT在FB13和YAGO3-10的100个测试实例上进行了评估。对于KGT5，我们使用我们的提示和响应进行训练，其他设置与其实现相同。我们输入设计好的提示到GPT-4和ChatGPT的Web界面以获取结果。

为了在多个任务上评估KG-LLM的性能，我们将KG-LLM与多种KG嵌入方法进行比较，包括TransE及其扩展、DistMult及其扩展、NTN、ConvKB、DOLORES、KG-BERT、StAR、KGT5等。我们还与两个最先进的LLM（ChatGPT和GPT-4）进行了比较。

## 实验过程

### 数据集和设置

在四个广泛使用的知识图谱基准数据集上进行了实验，分别是WN11、FB13、WN18RR和YAGO3-10。这些数据集包含了大量的实体、关系和三元组，可以有效地评估知识图谱补全方法的性能。实验中，作者们使用了与知识图谱嵌入相同的实体和关系文本描述作为输入。由于访问限制，他们对GPT-4和ChatGPT在FB13和YAGO3-10的100个测试实例上进行了评估。对于KGT5，他们使用自己的提示和响应进行训练，其他设置与其实现相同。他们将设计好的提示输入到GPT-4和ChatGPT的Web界面以获取结果。

### 结果评估

为了评估KG-LLM在知识图谱补全任务上的性能，将其与多种知识图谱嵌入方法进行了比较，包括TransE及其扩展、DistMult及其扩展、NTN、ConvKB、DOLORES、KG-BERT、StAR、KGT5等。此外，还与两个最先进的LLM（ChatGPT和GPT-4）进行了比较。实验结果表明，KG-LLM在多个知识图谱补全任务上取得了最先进的性能。特别是，KG-LLaMA-7B在YAGO3-10数据集上实现了最高的三元组分类准确率，甚至超过了GPT-4。

### 与其他方法的比较

他们详细比较了KG-LLM与其他知识图谱补全方法在不同数据集上的性能。在三元组分类任务上，KG-LLM在WN11和FB13数据集上的表现优于其他方法。在关系预测和实体预测任务上，KG-LLM同样取得了优异的成绩。这些结果表明，KG-LLM在知识图谱补全任务上具有较强的竞争力。

### 局限性

尽管KG-LLM在知识图谱补全任务上取得了显著的性能提升，但仍存在一些局限性。首先，该方法目前无法处理缺乏实体和关系文本描述的知识图谱。其次，他们尚未充分利用知识图谱的结构信息，这在实体预测任务中具有很大的潜力。未来的工作将致力于解决这些局限性，包括应用KG-LLM于其他自然语言处理任务、结合知识图谱的结构信息以及探索更有效的提示工程和上下文指令。



- 三篇多模态融合的文章
- 找一个代码复现
